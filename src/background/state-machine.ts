import type { ResearchSession, SessionState, AnalysisEntry, LLMUsage } from "../shared/types";
import { callGLM, callClaude, braveSearch } from "./llm-client";
import { POLL_INTERVAL_MS } from "../shared/constants";

let currentSession: ResearchSession | null = null;
let pollTimer: ReturnType<typeof setInterval> | null = null;
let keepAlivePort: chrome.runtime.Port | null = null;
let chatGptTabId: number | null = null;
const usage: LLMUsage = { glmCalls: 0, claudeCalls: 0 };

type StateListener = (session: ResearchSession) => void;
const listeners: StateListener[] = [];

export function onStateChange(fn: StateListener) {
  listeners.push(fn);
}

function notify() {
  if (currentSession) listeners.forEach((fn) => fn(currentSession!));
}

function transition(state: SessionState) {
  if (!currentSession) return;
  currentSession.state = state;
  notify();
}

function logProgress(step: string, detail: string) {
  if (!currentSession) return;
  currentSession.progressLog.push({ time: Date.now(), step, detail });
  notify();
}

export function getSession(): ResearchSession | null {
  return currentSession;
}

export function getUsage(): LLMUsage {
  return { ...usage };
}

// Keep MV3 service worker alive during long operations
let keepAliveInterval: ReturnType<typeof setInterval> | null = null;
function startKeepAlive() {
  if (keepAliveInterval) return;
  // Ping self every 25s to prevent 30s idle timeout
  keepAliveInterval = setInterval(() => {
    chrome.runtime.getPlatformInfo(() => {
      console.log("[CS-BG] keep-alive ping");
    });
  }, 25000);
  console.log("[CS-BG] keep-alive started");
}
function stopKeepAlive() {
  if (keepAliveInterval) {
    clearInterval(keepAliveInterval);
    keepAliveInterval = null;
    console.log("[CS-BG] keep-alive stopped");
  }
}

async function sendToTab(msg: { type: string; payload?: unknown }): Promise<any> {
  if (!chatGptTabId) throw new Error("No ChatGPT tab");
  return chrome.tabs.sendMessage(chatGptTabId, msg);
}

/**
 * Ensure content script is loaded on the target tab.
 * Manifest-declared content scripts only inject on NEW page loads after extension install.
 * For already-open tabs, we must inject programmatically.
 */
async function ensureContentScript(tabId: number): Promise<void> {
  try {
    const res = await chrome.tabs.sendMessage(tabId, { type: "PING" });
    if (res?.pong) {
      console.log("[CS-BG] Content script already active");
      return;
    }
  } catch {
    // Content script not loaded - inject it
  }

  console.log("[CS-BG] Injecting content script programmatically...");
  const manifest = chrome.runtime.getManifest();
  const files = manifest.content_scripts?.[0]?.js;
  if (!files || files.length === 0) {
    throw new Error("No content script files in manifest");
  }
  await chrome.scripting.executeScript({
    target: { tabId },
    files,
  });
  // Wait for script to initialize
  await new Promise((r) => setTimeout(r, 500));

  // Verify
  const verify = await chrome.tabs.sendMessage(tabId, { type: "PING" });
  if (!verify?.pong) {
    throw new Error("Content script injection failed");
  }
  console.log("[CS-BG] Content script injected and verified");
}

export async function startSession(
  topic: string,
  settings: { glmApiKey: string; claudeApiKey: string; maxRounds: number; autoMode: boolean },
  sessionId?: string
) {
  // Check if there's already an active session
  if (currentSession) {
    throw new Error(`Ïù¥ÎØ∏ Ïã§Ìñâ Ï§ëÏù∏ ÏÑ∏ÏÖòÏù¥ ÏûàÏäµÎãàÎã§: "${currentSession.topic}". Î®ºÏ†Ä ÌòÑÏû¨ ÏÑ∏ÏÖòÏùÑ Ï¢ÖÎ£åÌï¥Ï£ºÏÑ∏Ïöî.`);
  }

  // Find ChatGPT tab
  const tabs = await chrome.tabs.query({ url: ["*://chatgpt.com/*", "*://chat.openai.com/*"] });
  if (tabs.length === 0 || !tabs[0].id) {
    throw new Error("No ChatGPT tab found. Please open ChatGPT first.");
  }
  chatGptTabId = tabs[0].id;

  // Ensure content script is loaded on the tab
  await ensureContentScript(chatGptTabId);

  // Mark existing messages as seen so we don't process old ones
  await sendToTab({ type: "MARK_SEEN" });

  // Insert topic into ChatGPT input
  console.log("[CS-BG] Inserting topic into ChatGPT...");
  const autoSubmit = settings.autoMode;
  await sendToTab({
    type: "INSERT_QUESTION",
    payload: { question: topic, autoSubmit },
  });
  console.log(`[CS-BG] Topic inserted. ${autoSubmit ? 'Auto-submitting...' : 'User can review and press Enter.'}`);

  // Use provided sessionId from Gateway, or generate one if not provided
  const id = sessionId || Date.now().toString();
  console.log(`[CS-BG] Using session ID: ${id}`);

  currentSession = {
    id,
    topic,
    state: "WAITING_RESEARCH",
    round: 1,
    maxRounds: settings.maxRounds,
    autoMode: settings.autoMode,
    reports: [],
    analyses: [],
    progressLog: [],
    createdAt: Date.now(),
  };
  usage.glmCalls = 0;
  usage.claudeCalls = 0;

  logProgress("‚ùì ChatGPTÏóê Ïó∞Íµ¨ ÏßàÎ¨∏ Ï†ÑÏÜ°", topic.slice(0, 200));
  notify();
  startPolling(settings);
}

export function cancelSession() {
  console.log("[CS-BG] Canceling session - generating internal report before clearing");

  // Ìè¥ÎßÅ Ï§ëÏßÄ
  if (pollTimer) {
    clearInterval(pollTimer);
    pollTimer = null;
  }

  stopKeepAlive();

  // ÌòÑÏû¨ ÏÉÅÌÉúÎßå Ï†ÄÏû•ÌïòÍ≥† ÏÑ∏ÏÖò Ï¢ÖÎ£å
  if (currentSession) {
    logProgress("üõë ÏÑ∏ÏÖò Ï∑®ÏÜåÎê®", "ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ∏ÏÖòÏùÑ Ï∑®ÏÜåÌñàÏäµÎãàÎã§. ÎÇ¥Î∂Ä Î≥¥Í≥†ÏÑú ÏÉùÏÑ± Ï§ë...");

    // Generate internal report before clearing session
    const internalReport = generateFinalReport();
    console.log("[CS-BG] Internal report generated, length:", internalReport.length);

    // Store report in session before transition
    currentSession.finalReport = internalReport;

    transition("IDLE");
    notify(); // UI ÏóÖÎç∞Ïù¥Ìä∏Î•º ÏúÑÌï¥ ÎßàÏßÄÎßâ ÏÉÅÌÉú Ï†ÑÎã¨
  }

  // GPTÏóêÏÑú ÏÉà Ï±ÑÌåÖ ÏãúÏûë
  const tabId = chatGptTabId;
  if (tabId) {
    chrome.tabs.sendMessage(tabId, { type: "NEW_CHAT" }).catch(() => {
      console.warn("[CS-BG] Failed to start new chat (tab may be closed)");
    });
  }

  // currentSessionÏùÑ nullÎ°ú ÏÑ§Ï†ïÌïòÏó¨ Îã§Ïùå ÏÑ∏ÏÖò ÏãúÏûë Í∞ÄÎä•
  currentSession = null;
  chatGptTabId = null;
  console.log("[CS-BG] Session cancelled, ready for new session");
}

export async function stopSession() {
  if (!currentSession || !chatGptTabId) {
    if (pollTimer) clearInterval(pollTimer);
    pollTimer = null;
    stopKeepAlive();
    return;
  }

  // Ask ChatGPT to summarize the entire conversation
  const summaryPrompt = `ÏßÄÍ∏àÍπåÏßÄÏùò Î™®Îì† Ïó∞Íµ¨ ÎÇ¥Ïö©ÏùÑ Ï¢ÖÌï©ÌïòÏó¨ ÏµúÏ¢Ö Î≥¥Í≥†ÏÑúÎ•º ÏûëÏÑ±ÌïòÍ≥†, ÎßàÌÅ¨Îã§Ïö¥(.md) ÌååÏùºÎ°ú Îã§Ïö¥Î°úÎìúÌï† Ïàò ÏûàÍ≤å Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî.

Î≥¥Í≥†ÏÑú ÌòïÏãù:

# ÏµúÏ¢Ö Ïó∞Íµ¨ Î≥¥Í≥†ÏÑú: ${currentSession.topic}

## ÌïµÏã¨ Î∞úÍ≤¨ÏÇ¨Ìï≠
(Í∞ÄÏû• Ï§ëÏöîÌïú Î∞úÍ≤¨ 3-5Í∞ú)

## ÏÉÅÏÑ∏ Î∂ÑÏÑù
(Í∞Å Ï£ºÏ†úÎ≥Ñ Ïã¨Ï∏µ Î∂ÑÏÑù)

## ÌôïÏù∏Îêú ÏÇ¨Ïã§ vs Î∂àÌôïÏã§Ìïú Ï†ïÎ≥¥
(Ïã†Î¢∞ÎèÑ Íµ¨Î∂Ñ)

## Í≤∞Î°† Î∞è Ï†úÏñ∏
(ÏµúÏ¢Ö Í≤∞Î°†Í≥º Ìñ•ÌõÑ Ïó∞Íµ¨ Î∞©Ìñ•)

Î∞òÎìúÏãú ÎßàÌÅ¨Îã§Ïö¥ ÌååÏùº(.md)Î°ú Îã§Ïö¥Î°úÎìúÌï† Ïàò ÏûàÎèÑÎ°ù Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî.`;

  try {
    await sendToTab({
      type: "INSERT_QUESTION",
      payload: { question: summaryPrompt, autoSubmit: true },
    });
    logProgress("üìù ÏµúÏ¢Ö ÏöîÏïΩ ÏöîÏ≤≠", "ChatGPTÏóê Ï†ÑÏ≤¥ ÎåÄÌôî Í∏∞Î∞ò ÏµúÏ¢Ö Î≥¥Í≥†ÏÑú ÏûëÏÑ± ÏöîÏ≤≠");

    // Mark current messages as seen so we detect the final report as a NEW message
    await sendToTab({ type: "MARK_SEEN" });

    // Keep service worker alive while waiting for final report
    startKeepAlive();

    // Transition to WAITING_FINAL_REPORT state instead of IDLE
    transition("WAITING_FINAL_REPORT");
    // Keep polling to capture the final report
  } catch (e) {
    console.error("[CS-BG] Failed to insert summary request:", e);
    // If failed to send request, go to IDLE directly
    transition("IDLE");
    if (pollTimer) clearInterval(pollTimer);
    pollTimer = null;
    stopKeepAlive();
  }
}

function startPolling(settings: { glmApiKey: string; claudeApiKey: string; maxRounds: number; autoMode: boolean }) {
  if (pollTimer) clearInterval(pollTimer);

  pollTimer = setInterval(async () => {
    if (!currentSession || !chatGptTabId) return;

    try {
      // Handle WAITING_FINAL_REPORT state
      if (currentSession.state === "WAITING_FINAL_REPORT") {
        // Timeout: if waiting too long (3 min), fall back to internal report
        const waitStart = (currentSession as any)._waitFinalReportSince || Date.now();
        if (!(currentSession as any)._waitFinalReportSince) {
          (currentSession as any)._waitFinalReportSince = Date.now();
        }
        const elapsed = Date.now() - waitStart;
        if (elapsed > 180_000) {
          console.log("[CS-Extension] Final report timeout, using internal report");
          logProgress("‚ö†Ô∏è ÏµúÏ¢Ö Î≥¥Í≥†ÏÑú ÏãúÍ∞Ñ Ï¥àÍ≥º", "ÎÇ¥Î∂Ä Î≥¥Í≥†ÏÑúÎ°ú ÎåÄÏ≤¥Ìï©ÎãàÎã§");
          const internalReport = generateFinalReport();
          currentSession.finalReport = internalReport;
          transition("IDLE");
          if (pollTimer) clearInterval(pollTimer);
          pollTimer = null;
          stopKeepAlive();
          notify();
          currentSession = null;
          chatGptTabId = null;
          return;
        }

        // Check if ChatGPT is still streaming
        const statusRes = await sendToTab({ type: "CHECK_RESEARCH_STATUS" });
        if (statusRes?.inProgress) {
          console.log("[CS-Extension] ChatGPT still generating final report, waiting...");
          return;
        }

        // Check for new message (final report)
        const msgRes = await sendToTab({ type: "CHECK_NEW_MESSAGE" });
        if (!msgRes?.content) return; // No new message yet

        const finalReportContent = msgRes.content as string;
        console.log("[CS-Extension] Final report received, length:", finalReportContent.length);
        logProgress("üìã ÏµúÏ¢Ö Î≥¥Í≥†ÏÑú ÏàòÏã†", `${finalReportContent.length}Ïûê ÏµúÏ¢Ö Î≥¥Í≥†ÏÑú Ï†ÄÏû• ÏôÑÎ£å`);

        // Save final report
        currentSession.finalReport = finalReportContent;

        // Complete session
        transition("IDLE");
        if (pollTimer) clearInterval(pollTimer);
        pollTimer = null;
        stopKeepAlive();
        notify();

        // Start new chat for next session
        const tabId = chatGptTabId;
        if (tabId) {
          setTimeout(() => {
            chrome.tabs.sendMessage(tabId, { type: "NEW_CHAT" }).catch(() => {
              console.warn("[CS-BG] Failed to start new chat after final report");
            });
          }, 1000); // Wait 1 second for report to be fully displayed
        }

        // Clear session to allow new sessions
        currentSession = null;
        chatGptTabId = null;
        console.log("[CS-BG] Session completed, ready for new session");
        return;
      }

      // Handle WAITING_RESEARCH state
      if (currentSession.state !== "WAITING_RESEARCH") return;

      // If waiting for content growth (deep research mode), check if content has grown
      if (currentSession.waitingForGrowth) {
        const statusRes = await sendToTab({ type: "CHECK_RESEARCH_STATUS" });
        if (statusRes?.inProgress) {
          console.log("[CS-Extension] Deep research still in progress, waiting...");
          return;
        }
        const growthRes = await sendToTab({ type: "CHECK_CONTENT_GROWTH", payload: { minLength: 200 } });
        if (!growthRes?.content) return; // Not grown enough yet
        const grownContent = growthRes.content as string;
        console.log("[CS-Extension] Content growth detected, length:", grownContent.length);
        currentSession.waitingForGrowth = false;
        await processReport(grownContent, "Ïã¨Ï∏µÎ¶¨ÏÑúÏπò", settings);
        return;
      }

      // Check if ChatGPT is still streaming
      const statusRes = await sendToTab({ type: "CHECK_RESEARCH_STATUS" });
      if (statusRes?.inProgress) {
        console.log("[CS-Extension] ChatGPT still streaming, waiting...");
        return;
      }

      // Check for new message
      const msgRes = await sendToTab({ type: "CHECK_NEW_MESSAGE" });
      if (!msgRes?.content) return; // No new message yet

      const reportContent = msgRes.content as string;
      console.log("[CS-Extension] New message detected, length:", reportContent.length);

      // Skip very short responses ‚Äî likely deep research initial acknowledgment
      // (e.g. "I'll research this for you" before actual research starts)
      const MIN_REPORT_LENGTH = 200;
      if (reportContent.length < MIN_REPORT_LENGTH) {
        console.log("[CS-Extension] Response too short (" + reportContent.length + " chars), likely not a real report. Will monitor for content growth.");
        logProgress("‚è≥ ÏßßÏùÄ ÏùëÎãµ Í∞êÏßÄ", `${reportContent.length}Ïûê ‚Äî Ïã¨Ï∏µÎ¶¨ÏÑúÏπò ÏßÑÌñâ Ï§ëÏùº Ïàò ÏûàÏùå, ÎÇ¥Ïö© Ï¶ùÍ∞Ä ÎåÄÍ∏∞`);
        // Switch to content-growth monitoring mode
        if (!currentSession) return;
        currentSession.waitingForGrowth = true;
        return;
      }

      await processReport(reportContent, "", settings);
    } catch (err) {
      console.error("[CS-Extension] Poll error:", err);
    }
  }, POLL_INTERVAL_MS);
}

/**
 * Common logic after receiving a report: save ‚Üí analyze ‚Üí build enriched question ‚Üí insert ‚Üí advance round.
 */
async function processReport(
  reportContent: string,
  logLabel: string,
  settings: { glmApiKey: string; claudeApiKey: string; maxRounds: number; autoMode: boolean }
): Promise<void> {
  if (!currentSession) return;

  logProgress("üì• Î≥¥Í≥†ÏÑú ÏàòÏã†" + (logLabel ? ` (${logLabel})` : ""), `${reportContent.length}Ïûê ÏàòÏã† ÏôÑÎ£å`);

  currentSession.reports.push({
    round: currentSession.round,
    content: reportContent,
    extractedAt: Date.now(),
  });

  transition("ANALYZING");
  startKeepAlive();
  let analysis: AnalysisEntry;
  try {
    analysis = await analyzeReport(reportContent, settings);
  } finally {
    stopKeepAlive();
  }
  if (!currentSession) return;
  currentSession.analyses.push(analysis);

  transition("INSERTING_QUESTION");
  const synthesisSummary = analysis.claudeAnalysis
    .replace(/### Follow-up Question[\s\S]*$/, "")
    .trim()
    .slice(0, 2000);
  const searchSummary = analysis.searchResults.slice(0, 1000);

  let enrichedQuestion = analysis.followUpQuestion;
  if (synthesisSummary || searchSummary) {
    enrichedQuestion += `\n\n[Ï∞∏Í≥†: Ïô∏Î∂Ä Í≤ÄÏ¶ù Í≤∞Í≥º]\n`;
    if (searchSummary && searchSummary !== "(Í≤ÄÏÉâ Í≤∞Í≥º ÏóÜÏùå)") {
      enrichedQuestion += `${searchSummary}\n\n`;
    }
    if (synthesisSummary) {
      enrichedQuestion += `[Î∂ÑÏÑù ÏöîÏïΩ]\n${synthesisSummary}\n\n`;
    }
    enrichedQuestion += `ÏúÑ Ïô∏Î∂Ä Í≤ÄÏ¶ù Ï†ïÎ≥¥Î•º Ï∞∏Í≥†ÌïòÏó¨ Îçî Ï†ïÌôïÌïòÍ≥† ÍπäÏù¥ ÏûàÎäî Ïó∞Íµ¨Î•º ÏßÑÌñâÌï¥Ï£ºÏÑ∏Ïöî.`;
  }

  analysis.enrichedQuestion = enrichedQuestion;

  logProgress("‚ùì ChatGPTÏóê ÌõÑÏÜç ÏßàÎ¨∏ Ï†ÑÏÜ°", analysis.followUpQuestion.slice(0, 200));

  await sendToTab({
    type: "INSERT_QUESTION",
    payload: { question: enrichedQuestion, autoSubmit: currentSession.autoMode },
  });

  currentSession.round++;
  if (currentSession.round > currentSession.maxRounds) {
    stopSession();
  } else {
    transition("WAITING_RESEARCH");
  }
}

async function analyzeReport(
  report: string,
  settings: { glmApiKey: string; claudeApiKey: string }
): Promise<AnalysisEntry> {
  // Snapshot session data upfront ‚Äî currentSession can become null during async ops
  if (!currentSession) throw new Error("Session cancelled before analysis");
  const sessionSnapshot = {
    id: currentSession.id,
    topic: currentSession.topic,
    round: currentSession.round,
    maxRounds: currentSession.maxRounds,
    analyses: [...currentSession.analyses],
  };

  console.log("[CS-BG] analyzeReport START, report length:", report.length);
  logProgress("üîç ÌïµÏã¨ ÏÇ¨Ïã§ Ï∂îÏ∂ú Ï§ë", "GLMÏúºÎ°ú Î≥¥Í≥†ÏÑúÏóêÏÑú Í≤ÄÏ¶ù Í∞ÄÎä•Ìïú ÏÇ¨Ïã§ Ï∂îÏ∂ú...");

  // Extract key claims and search via Brave
  const extractPrompt = `‰ªé‰ª•‰∏ãÊä•Âëä‰∏≠ÊèêÂèñ3-5‰∏™ÊúÄÂÖ≥ÈîÆÁöÑÂèØÈ™åËØÅ‰∫ãÂÆûÂ£∞ÊòéÔºåÊØèË°å‰∏Ä‰∏™Ôºå‰ªÖËæìÂá∫Â£∞ÊòéÊñáÊú¨Ôºö\n${report.slice(0, 4000)}`;
  const extractResult = await callGLM(extractPrompt, settings.glmApiKey);
  usage.glmCalls++;
  notify();
  console.log("[CS-BG] Step 1 done, claims extracted:", extractResult.error || extractResult.text.slice(0, 200));

  const claims = extractResult.text.split("\n").filter((l) => l.trim().length > 5).slice(0, 5);
  logProgress("üåê Ïõπ Í≤ÄÏÉâ Ï§ë", `${claims.length}Í∞ú ÏÇ¨Ïã§Ïóê ÎåÄÌï¥ Brave Í≤ÄÏÉâ Ïã§Ìñâ...`);
  let searchContext = "";
  if (claims.length > 0) {
    // Sequential to avoid Brave 429 rate limiting
    const allResults: Awaited<ReturnType<typeof braveSearch>> = [];
    for (const claim of claims.slice(0, 3)) {
      const results = await braveSearch(claim.replace(/^\d+[.„ÄÅ]\s*/, ""), 2);
      allResults.push(...results);
      if (results.length > 0) await new Promise((r) => setTimeout(r, 500)); // rate limit delay
    }
    logProgress("üåê Ïõπ Í≤ÄÏÉâ ÏôÑÎ£å", `${allResults.length}Í±¥Ïùò Í≤ÄÏÉâ Í≤∞Í≥º ÌôïÎ≥¥`);
    console.log("[CS-BG] Step 2 done, search results:", allResults.length);
    if (allResults.length > 0) {
      searchContext = "\n\n## ÁΩëÁªúÊêúÁ¥¢ÁªìÊûú\n" + allResults.slice(0, 5).map((r) => `- [${r.title}](${r.url}): ${r.description.slice(0, 150)}`).join("\n");
    }
  } else {
    console.log("[CS-BG] Step 2 skipped, no claims");
  }

  logProgress("üß† Ï¢ÖÌï© Î∂ÑÏÑù Ï§ÄÎπÑ", "ClaudeÏóêÍ≤å Î≥¥Í≥†ÏÑú + Í≤ÄÏÉâ Í≤∞Í≥º Ï†ÑÎã¨...");

  // Build previous rounds summary for context
  const prevRounds = sessionSnapshot.analyses.map((a) =>
    `Round ${a.round}: "${a.followUpQuestion}"`
  ).join("\n");

  const round = sessionSnapshot.round;
  const maxRounds = sessionSnapshot.maxRounds;
  const progressRatio = round / maxRounds; // 0.2 ~ 1.0

  // Phase guidance based on research progress
  let phaseGuidance: string;
  if (progressRatio <= 0.25) {
    phaseGuidance = `EARLY PHASE (Í∏∞Ï¥à ÏàòÏßë): ÌïµÏã¨ ÏÇ¨Ïã§Í≥º Í∏∞Î≥∏ Íµ¨Ï°∞Î•º ÌååÏïÖÌïòÎäî Îã®Í≥ÑÏûÖÎãàÎã§. Ï£ºÏ†úÏùò ÌïµÏã¨ Î≥ÄÏàòÏôÄ ÌòÑÌô©ÏùÑ ÎÑìÍ≤å ÌÉêÏÉâÌïòÏÑ∏Ïöî.`;
  } else if (progressRatio <= 0.5) {
    phaseGuidance = `MID PHASE (Ïã¨Ìôî Î∂ÑÏÑù): ÌïµÏã¨ Î≥ÄÏàò Í∞ÑÏùò Ïù∏Í≥ºÍ¥ÄÍ≥ÑÏôÄ Íµ¨Ï°∞Ï†Å Ïó≠ÌïôÏùÑ ÌååÍ≥†ÎìúÎäî Îã®Í≥ÑÏûÖÎãàÎã§. "Ïôú?"ÏôÄ "Ïñ¥Îñ§ Î©îÏª§ÎãàÏ¶òÏúºÎ°ú?"Î•º ÏßàÎ¨∏ÌïòÏÑ∏Ïöî.`;
  } else if (progressRatio <= 0.75) {
    phaseGuidance = `LATE PHASE (Í≤ÄÏ¶ù¬∑ÎπÑÍµê): ÌôïÏù∏Îêú ÏÇ¨Ïã§ÏùÑ Îã§Î•∏ Í¥ÄÏ†ê/ÎπÑÍµêÍµ∞ÏúºÎ°ú ÍµêÏ∞® Í≤ÄÏ¶ùÌïòÎäî Îã®Í≥ÑÏûÖÎãàÎã§. Î∞òÎåÄ ÏùòÍ≤¨, Î¶¨Ïä§ÌÅ¨, ÎåÄÏïàÏ†Å Ìï¥ÏÑùÏùÑ ÌÉêÏÉâÌïòÏÑ∏Ïöî.`;
  } else {
    phaseGuidance = `FINAL PHASE (ÌÜµÌï©¬∑Ïã§Ï†Ñ): ÏßÄÍ∏àÍπåÏßÄÏùò Î∂ÑÏÑùÏùÑ Ï¢ÖÌï©ÌïòÏó¨ Ïã§Ìñâ Í∞ÄÎä•Ìïú Í≤∞Î°†ÏùÑ ÎèÑÏ∂úÌïòÎäî Îã®Í≥ÑÏûÖÎãàÎã§. Ï†ÑÏ≤¥Î•º ÌïòÎÇòÏùò ÌåêÎã® ÌîÑÎ†àÏûÑÏúºÎ°ú ÏóÆÎäî ÏßàÎ¨∏ÏùÑ ÌïòÏÑ∏Ïöî. Ïòà: Í≤∞Î°†Ï†Å ÌåêÎã®, Ïã§Ï†Ñ Ï†ÅÏö©, ÏãúÎÇòÎ¶¨Ïò§Î≥Ñ ÎåÄÏùë Îì±.`;
  }

  const systemPrompt = `You are a research synthesis coordinator investigating a specific topic. Your session persists across rounds ‚Äî you remember all previous analyses.

## CORE TOPIC (NEVER DRIFT FROM THIS)
"${sessionSnapshot.topic}"

## Your Role
- Synthesize each round's ChatGPT report with external evidence (Brave search results)
- Identify what is confirmed, what is uncertain, and what is missing
- Generate follow-up questions that DEEPEN understanding of the CORE TOPIC

## Research Phase Strategy
${phaseGuidance}

## Quality Rules for Follow-up Questions
- Every follow-up MUST directly relate to the CORE TOPIC
- Revisiting a previous angle from a DEEPER perspective (e.g., ÌòÑÏÉÅ‚ÜíÏõêÏù∏‚ÜíÏàòÏπò Í≤ÄÏ¶ù) is encouraged
- But do NOT ask the same question at the same depth ‚Äî always go deeper or shift perspective
- If the report drifts off-topic, steer the follow-up back to the core topic
- Prefer "HOW" and "WHY" questions over "WHAT" questions
- Ask about mechanisms, causal paths, and trade-offs rather than simple facts
- Think: "What would a domain expert ask next to build a complete judgment framework?"

## Output Format
Output EXACTLY three sections in this order ‚Äî no other text:

### Meta-Assessment
(Self-reflect on research trajectory so far. Answer briefly in 2-4 lines:)
- Axes explored so far: [list]
- Gaps remaining: [list]
- Self-diagnosis: repetitive? biased? shallow? drifting?
- Strategy adjustment for this round: [what to do differently]

### Synthesis
(Your analysis of this round's report + external evidence)

### Follow-up Question
(A single sentence question, informed by your meta-assessment)

## Rules
- Respond in the SAME language as the report
- No translations, no meta-commentary outside Meta-Assessment section, no markdown bold
- Meta-Assessment is for internal use ‚Äî be honest and critical about the research trajectory`;

  const claudePrompt = `## Round ${round}/${maxRounds}
${prevRounds ? `\n## Previous Follow-up Questions (avoid exact repetition, but deeper revisits OK)\n${prevRounds}\n` : ""}
## ChatGPT Report (this round)
${report.slice(0, 6000)}

## External Evidence (Brave Search)
${searchContext || "(No search results available)"}

Produce your synthesis and follow-up question now.`;

  logProgress("üß† Claude Ï¢ÖÌï© Î∂ÑÏÑù Ï§ë", "Ïó∞Íµ¨ Í≤∞Í≥º Ï¢ÖÌï© Î∞è ÌõÑÏÜç ÏßàÎ¨∏ ÏÉùÏÑ±...");
  let claudeResult: { text: string; error?: string };
  claudeResult = await callClaude(claudePrompt, "", systemPrompt, `cs-${sessionSnapshot.id}`);
  usage.claudeCalls++;
  notify();
  // If Claude proxy fails, fall back to GLM
  if (claudeResult.error) {
    logProgress("‚ö†Ô∏è Claude Ïã§Ìå®, GLM ÎåÄÏ≤¥", claudeResult.error);
    claudeResult = await callGLM(claudePrompt, settings.glmApiKey);
    usage.glmCalls++;
    notify();
  }
  if (claudeResult.error) {
    logProgress("‚ùå Ï¢ÖÌï© Î∂ÑÏÑù Ïã§Ìå®", claudeResult.error);
  } else {
    logProgress("üß† Ï¢ÖÌï© Î∂ÑÏÑù ÏôÑÎ£å", `${claudeResult.text.length}Ïûê Î∂ÑÏÑù Í≤∞Í≥º ÏÉùÏÑ±`);
  }

  // Parse meta-assessment (internal self-reflection)
  const metaMatch = claudeResult.text.match(/### Meta-Assessment\s*\n([\s\S]*?)(?=\n### Synthesis)/);
  const metaAssessment = metaMatch?.[1]?.trim() || "";

  // Extract synthesis (strip meta-assessment section)
  const synthesisOnward = claudeResult.text.replace(/### Meta-Assessment[\s\S]*?(?=\n### Synthesis)/, "").trim();

  const questionMatch = synthesisOnward.match(/### Follow-up Question\s*\n([\s\S]*?)(?:\n###|$)/);
  let followUpQuestion = questionMatch?.[1]?.trim() || "Please provide more details on the uncertain aspects.";
  // Extract only the actual question ‚Äî first non-empty line that looks like a question
  const lines = followUpQuestion.split("\n").map((l) => l.trim()).filter((l) => l.length > 10);
  if (lines.length > 0) {
    // Take the first substantive line, strip markdown bold markers
    followUpQuestion = lines[0].replace(/^\*\*/, "").replace(/\*\*$/, "");
  }

  if (metaAssessment) {
    logProgress("üîÑ ÏûêÏ≤¥ Ï†ÑÎûµ Ï°∞Ï†ï", metaAssessment.split("\n")[0]?.slice(0, 80) || "Ï†ÑÎûµ Î¶¨Î∑∞ ÏôÑÎ£å");
  }

  return {
    round: sessionSnapshot.round,
    glmClaims: extractResult.text,
    searchResults: searchContext || "(Í≤ÄÏÉâ Í≤∞Í≥º ÏóÜÏùå)",
    claudeAnalysis: synthesisOnward,
    metaAssessment,
    followUpQuestion,
    enrichedQuestion: "", // will be filled by caller
    glmVerification: searchContext || "(Í≤ÄÏÉâ Í≤∞Í≥º ÏóÜÏùå)", // backward compat
    createdAt: Date.now(),
  };
}

export function confirmAndProceed(settings: { glmApiKey: string; claudeApiKey: string; maxRounds: number; autoMode: boolean }) {
  if (!currentSession || currentSession.state !== "WAITING_CONFIRM") return;
  currentSession.round++;
  if (currentSession.round > currentSession.maxRounds) {
    stopSession();
  } else {
    transition("WAITING_RESEARCH");
    startPolling(settings);
  }
}

export function generateFinalReport(): string {
  if (!currentSession) return "";

  const createdDate = new Date(currentSession.createdAt).toLocaleString("ko-KR");
  const currentRound = currentSession.round > currentSession.maxRounds ? currentSession.maxRounds : currentSession.round - 1;

  let report = `# Ïó∞Íµ¨ Î≥¥Í≥†ÏÑú: ${currentSession.topic}\n\n`;
  report += `- ÏÉùÏÑ±Ïùº: ${createdDate}\n`;
  report += `- Ï¥ù ÎùºÏö¥Îìú: ${currentRound}/${currentSession.maxRounds}\n`;
  report += `- GLM Ìò∏Ï∂ú: ${usage.glmCalls}Ìöå | Claude Ìò∏Ï∂ú: ${usage.claudeCalls}Ìöå\n`;
  report += `\n---\n\n`;

  // Add ChatGPT final report at the top if available
  if (currentSession.finalReport) {
    report += `## ChatGPT ÏµúÏ¢Ö Î≥¥Í≥†ÏÑú\n\n`;
    report += `${currentSession.finalReport}\n\n`;
    report += `---\n\n`;
  }

  // Generate report for each completed round ‚Äî full record of all data
  for (let i = 0; i < currentSession.analyses.length; i++) {
    const analysis = currentSession.analyses[i];
    const chatReport = currentSession.reports[i];

    report += `## Round ${analysis.round}\n\n`;

    if (chatReport) {
      report += `### 1. ChatGPT Ïó∞Íµ¨ Î≥¥Í≥†ÏÑú\n\n`;
      report += `${chatReport.content}\n\n`;
    }

    if (analysis.glmClaims) {
      report += `### 2. GLM Ï∂îÏ∂ú ÌïµÏã¨ ÏÇ¨Ïã§\n\n`;
      report += `${analysis.glmClaims}\n\n`;
    }

    if (analysis.searchResults && analysis.searchResults !== "(Í≤ÄÏÉâ Í≤∞Í≥º ÏóÜÏùå)") {
      report += `### 3. Brave Ïõπ Í≤ÄÏÉâ Í≤∞Í≥º\n\n`;
      report += `${analysis.searchResults}\n\n`;
    }

    if (analysis.metaAssessment) {
      report += `### 4. Claude ÏûêÏ≤¥ Ï†ÑÎûµ ÌèâÍ∞Ä\n\n`;
      report += `${analysis.metaAssessment}\n\n`;
    }

    report += `### 5. Claude Ï¢ÖÌï© Î∂ÑÏÑù\n\n`;
    report += `${analysis.claudeAnalysis}\n\n`;

    report += `### 6. ÌõÑÏÜç ÏßàÎ¨∏ (ÏõêÎ≥∏)\n\n`;
    report += `> ${analysis.followUpQuestion}\n\n`;

    if (analysis.enrichedQuestion && analysis.enrichedQuestion !== analysis.followUpQuestion) {
      report += `### 7. ChatGPTÏóê Ï†ÑÎã¨Îêú Ï†ÑÏ≤¥ ÏßàÎ¨∏\n\n`;
      report += `${analysis.enrichedQuestion}\n\n`;
    }

    report += `---\n\n`;
  }

  return report;
}
